{
    "answer": "'''\n\n# Import necessary libraries\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\n# Tokenize the texts and remove stopwords\ngroup1_tokens = [word for word in word_tokenize(text) if word.isalpha() for text in Group1]\ngroup2_tokens = [word for word in word_tokenize(text) if word.isalpha() for text in Group2]\n\n# Create stopword sets\nstop_words = set(stopwords.words('english'))\n\n# Remove stopwords from the tokens\ngroup1_tokens = [word for word in group1_tokens if word.lower() not in stop_words]\ngroup2_tokens = [word for word in group2_tokens if word.lower() not in stop_words]\n\n# Count the frequency of each word\ngroup1_counts = Counter(group1_tokens)\ngroup2_counts = Counter(group2_tokens)\n\n# Find the words that are not in both groups\nall_words = set(group1_counts.keys()).union(set(group2_counts.keys()))\ngroup1_only = [word for word in all_words if word not in group2_counts]\ngroup2_only = [word for word in all_words if word not in group1_counts]\n\n# Print the results\nprint(\"Group 1 only:\", group1_only"
}